{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flask on Google Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld838RDq-Nse"
      },
      "source": [
        "Flask on Google Colab\n",
        "\n",
        "https://medium.com/@kshitijvijay271199/flask-on-google-colab-f6525986797b\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm7rQf4o-FkR",
        "outputId": "77230cb1-791f-4063-c9a9-7c5d74cc3b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEUFNtFvEvfB",
        "outputId": "1f2c3ad8-d522-4c9e-e3d0-27e96ae1da8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#montagem padrao\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Y66wnFWLrF"
      },
      "source": [
        "#copiar checkpooint do drive para area de trabalho do colab\n",
        "!cp -r '/content/drive/My Drive/final_model_VGG16.h5' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqiCwqaBxyo5"
      },
      "source": [
        "#copiar checkpooint do drive para area de trabalho do colab\n",
        "!cp -r '/content/drive/My Drive/final_model_Xception.h5' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYen23IW4GXB"
      },
      "source": [
        "#copiar flask static files do drive para area de trabalho do colab\n",
        "!cp -r '/content/drive/My Drive/flask_files/static' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmD2YUj-4Hb5"
      },
      "source": [
        "#copiar flask templates files do drive para area de trabalho do colab\n",
        "!cp -r '/content/drive/My Drive/flask_files/templates' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBSEhHZgMRT1"
      },
      "source": [
        "#copiar checkpoints para area de trabalho do colab\n",
        "!cp -r '/content/drive/My Drive/checkpoint' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JzoOxLIEKSE"
      },
      "source": [
        "#escolhendo o modelo\n",
        "MODELO = '/content/final_model_Xception.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKu0IE16E86I"
      },
      "source": [
        "# Testando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qelX6nB0AdA4",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "\n",
        "modeljson = '/content/checkpoint/model_X.json'\n",
        "modeljson_weights = '/content/checkpoint/model_X_weights.h5'\n",
        "\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(224, 224))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 224, 224, 3)\n",
        "\t# center pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - [123.68, 116.779, 103.939]\n",
        "\treturn img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('/content/test_dog.jpg')\n",
        "\t# load model\n",
        "\t#model = load_model('/content/final_model_VGG16.h5')\n",
        "\t#model = load_model('/content/final_model_Xception.h5')\n",
        "\n",
        "\t# load json and create model\n",
        "\twith open(modeljson, 'r') as json_file:\n",
        "\t\tloaded_model_json = json_file.read()\n",
        "\n",
        "\tmodel = model_from_json(loaded_model_json)\n",
        "\t# load weights into new model\n",
        "\tmodel.load_weights(modeljson_weights)\n",
        "\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\tprint(result)\n",
        "\tif result[0]>0.5:\n",
        "\t\tprint( \" is a dog\")\n",
        "\telse:\n",
        "\t\tprint( \" is a cat\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6obxqUryDIBj",
        "cellView": "both",
        "outputId": "d896ea33-c74a-4ec8-a0b9-712ac37844d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#@title\n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99939466]]\n",
            " is a dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vLLFmnD2JxT"
      },
      "source": [
        "# Running Flask CATDOG Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oblKwwQDIfT",
        "cellView": "both",
        "outputId": "09e789ce-e68c-431c-e0e8-99774105539e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "#@title Flask Code\n",
        "# USAGE\n",
        "# Start the server:\n",
        "# \tpython run_keras_server.py\n",
        "# Submit a request via cURL:\n",
        "# \tcurl -X POST -F image=@dog.jpg 'http://localhost:5000/predict'\n",
        "# Submita a request via Python:\n",
        "#\tpython simple_request.py\n",
        "\n",
        "# import the necessary packages\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications import imagenet_utils\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from flask import Flask, request, render_template, jsonify, abort, url_for, redirect\n",
        "import io\n",
        "from keras.models import load_model\n",
        "#from keras.applications import VGG16\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# initialize our Flask application and the Keras model\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "model = None\n",
        "#FINAL_MODEL_VGG16 = MODELO\n",
        "modeljson = '/content/checkpoint/model_X.json'\n",
        "modeljson_weights = '/content/checkpoint/model_X_weights.h5'\n",
        "\n",
        "\n",
        "def load_modelo():\n",
        "\t# load the pre-trained Keras model (here we are using a model\n",
        "\t# pre-trained on ImageNet and provided by Keras, but you can\n",
        "\t# substitute in your own networks just as easily)\n",
        "\tglobal model\n",
        "\t# load model\n",
        "\t#model = load_model(FINAL_MODEL_VGG16)\n",
        "\t# load json and create model\n",
        "\twith open(modeljson, 'r') as json_file:\n",
        "\t\tloaded_model_json = json_file.read()\n",
        "\n",
        "\tmodel = model_from_json(loaded_model_json)\n",
        "\t# load weights into new model\n",
        "\tmodel.load_weights(modeljson_weights)\n",
        "\n",
        "\n",
        "def prepare_image(image, target):\n",
        "\t# if the image mode is not RGB, convert it\n",
        "\tif image.mode != \"RGB\":\n",
        "\t\timage = image.convert(\"RGB\")\n",
        "\n",
        "\t# resize the input image and preprocess it\n",
        "\timage = image.resize(target)\n",
        "\timage = img_to_array(image)\n",
        "\timage = np.expand_dims(image, axis=0)\n",
        "\timage = imagenet_utils.preprocess_input(image)\n",
        "\n",
        "\t# return the processed image\n",
        "\treturn image\n",
        "\n",
        "\n",
        "def its_cat_or_dog(predict):\n",
        "  print(predict[0])\n",
        "  if predict[0]>0.5:\n",
        "    return ( \" is a dog\")\n",
        "  else:\n",
        "    return  \" is a cat\"\n",
        "\n",
        "\n",
        "# @app.route(\"/\")\n",
        "# def hello():\n",
        "#     return \"Hello World!\"\n",
        "\n",
        "@app.route(\"/\")\n",
        "@app.route(\"/base\")\n",
        "def base():\n",
        "    return render_template('dashboard.html')\n",
        "\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "\t# initialize the data dictionary that will be returned from the\n",
        "\t# view\n",
        "\tdata = {\"success\": False}\n",
        "\n",
        "\t# ensure an image was properly uploaded to our endpoint\n",
        "\tif request.method == \"POST\":\n",
        "\t\tif request.files.get(\"image\"):\n",
        "\t\t\t# read the image in PIL format\n",
        "\t\t\timage = request.files[\"image\"].read()\n",
        "\t\t\timage = Image.open(io.BytesIO(image))\n",
        "\n",
        "\t\t\t# preprocess the image and prepare it for classification\n",
        "\t\t\timage = prepare_image(image, target=(224, 224))\n",
        "\n",
        "\t\t\t# classify the input image and then initialize the list\n",
        "\t\t\t# of predictions to return to the client\n",
        "\t\t\tpreds = model.predict(image)\n",
        "\t\t\tresults = its_cat_or_dog(preds)\n",
        "   \n",
        "\t\t\tdata[\"predictions\"] = []\n",
        "\n",
        "\t\t\t# loop over the results and add them to the list of\n",
        "\t\t\t# returned predictions\n",
        "\t\t\tr = {\"label\": results, \"probability\": float(preds[0])}\n",
        "\t\t\tdata[\"predictions\"].append(r)\n",
        "\n",
        "\t\t\t# indicate that the request was a success\n",
        "\t\t\tdata[\"success\"] = True\n",
        "\n",
        "\t# return the data dictionary as a JSON response\n",
        "\treturn jsonify(data)\n",
        "\n",
        "\n",
        "# if this is the main thread of execution first load the model and\n",
        "# then start the server\n",
        "if __name__ == \"__main__\":\n",
        "\tprint((\"* Loading Keras model and Flask starting server...\"\n",
        "            \"please wait until server has fully started\"))\n",
        "\tload_modelo()\n",
        "\tapp.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Loading Keras model and Flask starting server...please wait until server has fully started\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://2514c0003f84.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [28/Oct/2020 03:13:12] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Oct/2020 03:13:12] \"\u001b[37mGET /static/image/header_foto.jpeg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Oct/2020 03:13:14] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [28/Oct/2020 03:13:19] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Oct/2020 03:13:34] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1.2909078e-05]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [28/Oct/2020 03:13:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.9993746]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae-FrCB0MZZH"
      },
      "source": [
        "# Nova seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwmQMDLvEk2"
      },
      "source": [
        "model.save_weights(\"Xcept_weights.hs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUpoh1D-vji2"
      },
      "source": [
        "from pathlib import Path\n",
        "Path('/content/Xcept_weights.hs.index').stat().st_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCSU9U9Iw1L1"
      },
      "source": [
        "#load weights\n",
        "model.load_weights(\"weights.best.hdf5\")\n",
        "#compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[ 'accuracy'])\n",
        "print(\"Created model and loaded weights from file\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5nwjwxGy5CM",
        "outputId": "d90f0cb6-a63e-4e17-eb8c-07e70e8e4b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_X.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_X_weights.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrDCpL5eBvqB"
      },
      "source": [
        "#copiar checkpoints para area de trabalho do colab\n",
        "!cp -r '/content/drive/My Drive/checkpoint' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgt1ICfnzCNV",
        "outputId": "a4f09bdc-f137-4b73-cb35-915c12d620a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "modeljson = '/content/checkpoint/model_X.json'\n",
        "modeljson_weights = '/content/checkpoint/model_X_weights.h5'\n",
        "# load json and create model\n",
        "json_file = open(modeljson, 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(modeljson_weights)\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJJO351mDd8k",
        "outputId": "df6ad2a9-762c-4075-b35f-51b924ffb6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(loaded_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f34c402cc50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "916ClaheDzI2",
        "outputId": "bc1471fe-0f32-434c-9b16-de3fb618999c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 7, 7, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_22  (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 21,123,881\n",
            "Trainable params: 21,069,353\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}